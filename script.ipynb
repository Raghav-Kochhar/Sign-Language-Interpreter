{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVVTE0J_2myl"
      },
      "outputs": [],
      "source": [
        "!pip install yt-dlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LW43TLUr2W58",
        "outputId": "164fb07c-8bcc-4e87-f1f9-b00e698caa49"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import logging\n",
        "import yaml\n",
        "from dataclasses import dataclass, fields\n",
        "from typing import List, Dict, Optional, Tuple\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.transforms import RandomHorizontalFlip, RandomRotation, ColorJitter\n",
        "from tqdm import tqdm\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from google.colab import drive\n",
        "import requests\n",
        "import yt_dlp\n",
        "import time\n",
        "import subprocess\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
        ")\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class VideoInfo:\n",
        "    org_text: str\n",
        "    clean_text: str\n",
        "    start_time: float\n",
        "    signer_id: int\n",
        "    signer: int\n",
        "    start: int\n",
        "    end: int\n",
        "    file: str\n",
        "    label: int\n",
        "    height: float\n",
        "    fps: float\n",
        "    end_time: float\n",
        "    url: str\n",
        "    text: str\n",
        "    box: List[float]\n",
        "    width: float\n",
        "    review: Optional[bool] = None\n",
        "\n",
        "\n",
        "def load_config(config_path: str) -> Dict:\n",
        "    with open(config_path, \"r\") as f:\n",
        "        return yaml.safe_load(f)\n",
        "\n",
        "\n",
        "def download_video(\n",
        "    video_info: VideoInfo, output_path: str, max_retries: int = 3\n",
        ") -> Optional[str]:\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            url = video_info.url\n",
        "            if \"youtube.com\" in url or \"youtu.be\" in url:\n",
        "                ydl_opts = {\n",
        "                    \"format\": \"bestvideo[ext=mp4][height<=360]/best[ext=mp4][height<=360]/best[ext=mp4]/best\",\n",
        "                    \"outtmpl\": output_path,\n",
        "                    \"no_warnings\": True,\n",
        "                    \"quiet\": True,\n",
        "                    \"no_checkcertificate\": True,\n",
        "                    \"nocheckcertificate\": True,\n",
        "                    \"ignoreerrors\": False,\n",
        "                    \"logtostderr\": False,\n",
        "                    \"nopart\": True,\n",
        "                    \"no_playlist\": True,\n",
        "                    \"postprocessors\": [\n",
        "                        {\n",
        "                            \"key\": \"FFmpegVideoConvertor\",\n",
        "                            \"preferedformat\": \"mp4\",\n",
        "                        }\n",
        "                    ],\n",
        "                    \"postprocessor_args\": [\n",
        "                        \"-an\",  # Remove audio\n",
        "                        \"-vcodec\",\n",
        "                        \"libx264\",\n",
        "                        \"-preset\",\n",
        "                        \"ultrafast\",\n",
        "                        \"-crf\",\n",
        "                        \"23\",\n",
        "                    ],\n",
        "                }\n",
        "                with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                    ydl.download([url])\n",
        "            else:\n",
        "                if not url.startswith((\"http://\", \"https://\")):\n",
        "                    url = \"https://\" + url\n",
        "                response = requests.get(url, stream=True)\n",
        "                response.raise_for_status()\n",
        "                with open(output_path, \"wb\") as f:\n",
        "                    for chunk in response.iter_content(chunk_size=8192):\n",
        "                        f.write(chunk)\n",
        "            return output_path\n",
        "        except Exception as e:\n",
        "            logging.warning(\n",
        "                f\"Attempt {attempt + 1} failed to download video from {url}: {str(e)}\"\n",
        "            )\n",
        "            time.sleep(1)\n",
        "\n",
        "    logging.error(f\"Failed to download video after {max_retries} attempts: {url}\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def trim_video(\n",
        "    input_path: str, start_time: float, end_time: float, output_path: str\n",
        ") -> Optional[str]:\n",
        "    try:\n",
        "        cmd = [\n",
        "            \"ffmpeg\",\n",
        "            \"-i\",\n",
        "            input_path,\n",
        "            \"-ss\",\n",
        "            str(start_time),\n",
        "            \"-to\",\n",
        "            str(end_time),\n",
        "            \"-c:v\",\n",
        "            \"libx264\",\n",
        "            \"-preset\",\n",
        "            \"ultrafast\",\n",
        "            \"-an\",\n",
        "            \"-y\",\n",
        "            output_path,\n",
        "        ]\n",
        "        subprocess.run(\n",
        "            cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL\n",
        "        )\n",
        "        os.remove(input_path)\n",
        "        return output_path\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Failed to process video {input_path}: {str(e)}\")\n",
        "        if os.path.exists(input_path):\n",
        "            os.remove(input_path)\n",
        "        return None\n",
        "\n",
        "\n",
        "def is_valid_video(file_path: str) -> bool:\n",
        "    try:\n",
        "        cap = cv2.VideoCapture(file_path)\n",
        "        if not cap.isOpened():\n",
        "            return False\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            return False\n",
        "        cap.release()\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error validating video {file_path}: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def process_video(\n",
        "    video_info: VideoInfo, temp_dir: str, final_dir: str\n",
        ") -> Optional[str]:\n",
        "    signer = video_info.signer_id if video_info.signer_id != -1 else video_info.signer\n",
        "    output_filename = f\"{video_info.clean_text}_{signer}.mp4\"\n",
        "    final_path = os.path.join(final_dir, output_filename)\n",
        "\n",
        "    if os.path.exists(final_path):\n",
        "        logging.info(f\"Video {output_filename} already exists, skipping...\")\n",
        "        return final_path\n",
        "\n",
        "    temp_filename = f\"temp_{video_info.clean_text}_{signer}.mp4\"\n",
        "    temp_path = os.path.join(temp_dir, temp_filename)\n",
        "\n",
        "    downloaded_path = download_video(video_info, temp_path)\n",
        "    if downloaded_path and is_valid_video(downloaded_path):\n",
        "        return trim_video(\n",
        "            downloaded_path, video_info.start_time, video_info.end_time, final_path\n",
        "        )\n",
        "    else:\n",
        "        logging.error(f\"Invalid or corrupted video: {video_info.url}\")\n",
        "        if downloaded_path and os.path.exists(downloaded_path):\n",
        "            os.remove(downloaded_path)\n",
        "        return None\n",
        "\n",
        "\n",
        "def download_and_process_videos(data_dir: str, config: Dict) -> Tuple[int, int]:\n",
        "    temp_dir = \"/content/temp_videos\"\n",
        "    os.makedirs(temp_dir, exist_ok=True)\n",
        "\n",
        "    final_dir = os.path.join(\"/content/drive/MyDrive\", config[\"drive_video_folder\"])\n",
        "    os.makedirs(final_dir, exist_ok=True)\n",
        "\n",
        "    all_videos = []\n",
        "    for split in [\"train\", \"test\", \"val\"]:\n",
        "        json_file_path = os.path.join(data_dir, f\"MSASL_{split}.json\")\n",
        "        if os.path.exists(json_file_path):\n",
        "            with open(json_file_path, \"r\") as f:\n",
        "                videos = json.load(f)\n",
        "                for v in videos:\n",
        "                    if isinstance(v[\"box\"], str):\n",
        "                        v[\"box\"] = eval(v[\"box\"])\n",
        "                    video_info_fields = set(field.name for field in fields(VideoInfo))\n",
        "                    filtered_v = {k: v[k] for k in video_info_fields if k in v}\n",
        "                    all_videos.append(VideoInfo(**filtered_v))\n",
        "        else:\n",
        "            logging.warning(f\"File {json_file_path} not found. Skipping...\")\n",
        "\n",
        "    logging.info(f\"Total videos available: {len(all_videos)}\")\n",
        "\n",
        "    # Group videos by class\n",
        "    class_videos = {}\n",
        "    for video in all_videos:\n",
        "        if video.label not in class_videos:\n",
        "            class_videos[video.label] = []\n",
        "        class_videos[video.label].append(video)\n",
        "\n",
        "    processed_labels = set()\n",
        "    total_classes = len(class_videos)\n",
        "\n",
        "    def process_class(label):\n",
        "        videos = class_videos[label]\n",
        "        for video_info in videos:\n",
        "            output_filename = f\"{video_info.clean_text}_{video_info.signer_id if video_info.signer_id != -1 else video_info.signer}.mp4\"\n",
        "            final_path = os.path.join(final_dir, output_filename)\n",
        "            if os.path.exists(final_path):\n",
        "                logging.info(f\"Video for class {label} already exists, skipping...\")\n",
        "                return label\n",
        "            result = process_video(video_info, temp_dir, final_dir)\n",
        "            if result:\n",
        "                logging.info(f\"Successfully processed video for class {label}\")\n",
        "                return label\n",
        "        return None\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=config.get(\"max_workers\", 4)) as executor:\n",
        "        futures = [\n",
        "            executor.submit(process_class, label) for label in class_videos.keys()\n",
        "        ]\n",
        "        for future in tqdm(\n",
        "            as_completed(futures), total=total_classes, desc=\"Processing classes\"\n",
        "        ):\n",
        "            processed_label = future.result()\n",
        "            if processed_label is not None:\n",
        "                processed_labels.add(processed_label)\n",
        "\n",
        "    logging.info(\n",
        "        f\"Successfully processed videos for {len(processed_labels)} out of {total_classes} classes\"\n",
        "    )\n",
        "\n",
        "    return len(processed_labels), total_classes\n",
        "\n",
        "\n",
        "class MSASLDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        data_dir: str,\n",
        "        config: Dict,\n",
        "        transform: Optional[transforms.Compose] = None,\n",
        "    ):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.video_dir = os.path.join(\n",
        "            \"/content/drive/MyDrive\", config[\"drive_video_folder\"]\n",
        "        )\n",
        "\n",
        "        with open(os.path.join(data_dir, \"MSASL_classes.json\"), \"r\") as f:\n",
        "            self.classes = json.load(f)\n",
        "\n",
        "        self.data = []\n",
        "        for split in [\"train\", \"val\", \"test\"]:\n",
        "            split_path = os.path.join(data_dir, f\"MSASL_{split}.json\")\n",
        "            if os.path.exists(split_path):\n",
        "                with open(split_path, \"r\") as f:\n",
        "                    all_data = json.load(f)\n",
        "                    for item in all_data:\n",
        "                        video_path = os.path.join(\n",
        "                            self.video_dir,\n",
        "                            f\"{item['clean_text']}_{item['signer_id'] if item['signer_id'] != -1 else item['signer']}.mp4\",\n",
        "                        )\n",
        "                        item[\"video_path\"] = video_path\n",
        "                        self.data.append(item)\n",
        "\n",
        "        available_labels = set(item[\"label\"] for item in self.data)\n",
        "        self.class_to_idx = {\n",
        "            label: idx for idx, label in enumerate(sorted(available_labels))\n",
        "        }\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        item = self.data[idx]\n",
        "        label = self.class_to_idx[item[\"label\"]]\n",
        "        video_path = item[\"video_path\"]\n",
        "\n",
        "        try:\n",
        "            cap = cv2.VideoCapture(video_path)\n",
        "            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_count // 2)\n",
        "            ret, frame = cap.read()\n",
        "            cap.release()\n",
        "\n",
        "            if not ret:\n",
        "                raise Exception(\"Failed to read frame\")\n",
        "\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        except Exception:\n",
        "            # If there's any error reading the video, return a blank frame\n",
        "            frame = np.zeros((224, 224, 3), dtype=np.uint8)\n",
        "\n",
        "        frame = cv2.resize(frame, (224, 224))\n",
        "\n",
        "        if self.transform:\n",
        "            frame = self.transform(frame)\n",
        "\n",
        "        return frame, label\n",
        "\n",
        "\n",
        "def get_data_loaders(data_dir: str, config: Dict):\n",
        "    train_transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.ToPILImage(),\n",
        "            RandomHorizontalFlip(),\n",
        "            RandomRotation(10),\n",
        "            ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    val_test_transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    full_dataset = MSASLDataset(data_dir, config, transform=None)\n",
        "\n",
        "    train_size = int(config[\"train_ratio\"] * len(full_dataset))\n",
        "    val_size = int(config[\"val_ratio\"] * len(full_dataset))\n",
        "    test_size = len(full_dataset) - train_size - val_size\n",
        "\n",
        "    train_dataset, val_test_dataset = torch.utils.data.random_split(\n",
        "        full_dataset, [train_size, val_size + test_size]\n",
        "    )\n",
        "    val_dataset, test_dataset = torch.utils.data.random_split(\n",
        "        val_test_dataset, [val_size, test_size]\n",
        "    )\n",
        "\n",
        "    train_dataset.dataset.transform = train_transform\n",
        "    val_dataset.dataset.transform = val_test_transform\n",
        "    test_dataset.dataset.transform = val_test_transform\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        shuffle=True,\n",
        "        num_workers=config[\"num_workers\"],\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        shuffle=False,\n",
        "        num_workers=config[\"num_workers\"],\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        shuffle=False,\n",
        "        num_workers=config[\"num_workers\"],\n",
        "    )\n",
        "\n",
        "    logging.info(f\"Train set size: {len(train_dataset)}\")\n",
        "    logging.info(f\"Validation set size: {len(val_dataset)}\")\n",
        "    logging.info(f\"Test set size: {len(test_dataset)}\")\n",
        "\n",
        "    return train_loader, val_loader, test_loader, full_dataset\n",
        "\n",
        "\n",
        "class SignLanguageModel(nn.Module):\n",
        "    def __init__(self, num_classes: int):\n",
        "        super(SignLanguageModel, self).__init__()\n",
        "\n",
        "        # Load the pre-trained EfficientNetV2-S model\n",
        "        self.base_model = efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.DEFAULT)\n",
        "\n",
        "        # Freeze early layers\n",
        "        for param in list(self.base_model.parameters())[:-30]:\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Replace the last fully connected layer\n",
        "        num_ftrs = self.base_model.classifier[1].in_features\n",
        "        self.base_model.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.2), nn.Linear(num_ftrs, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n",
        "\n",
        "    def to_torchscript(self, example_input):\n",
        "        self.eval()\n",
        "        traced_script_module = torch.jit.trace(self, example_input)\n",
        "        return traced_script_module\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience: int = 7, min_delta: float = 0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss: float):\n",
        "        score = -val_loss\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "        elif score < self.best_score + self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.counter = 0\n",
        "\n",
        "\n",
        "def train_model(data_dir: str, config: Dict):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    logging.info(f\"Using device: {device}\")\n",
        "\n",
        "    train_loader, val_loader, test_loader, full_dataset = get_data_loaders(\n",
        "        data_dir, config\n",
        "    )\n",
        "\n",
        "    num_classes = len(full_dataset.class_to_idx)\n",
        "    logging.info(f\"Number of classes: {num_classes}\")\n",
        "\n",
        "    model = SignLanguageModel(num_classes).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, \"min\", patience=5, factor=0.5\n",
        "    )\n",
        "    early_stopping = EarlyStopping(patience=10)\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    best_val_accuracy = 0.0\n",
        "\n",
        "    for epoch in range(config[\"num_epochs\"]):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        for inputs, labels in tqdm(\n",
        "            train_loader, desc=f\"Epoch {epoch+1}/{config['num_epochs']}\"\n",
        "        ):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with autocast():\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_accuracy = 100 * train_correct / train_total\n",
        "        logging.info(\n",
        "            f\"Epoch {epoch+1}/{config['num_epochs']}, Training Loss: {train_loss/len(train_loader):.4f}, Training Accuracy: {train_accuracy:.2f}%\"\n",
        "        )\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_accuracy = 100 * val_correct / val_total\n",
        "        logging.info(\n",
        "            f\"Validation Loss: {val_loss/len(val_loader):.4f}, Validation Accuracy: {val_accuracy:.2f}%\"\n",
        "        )\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "        early_stopping(val_loss)\n",
        "\n",
        "        if val_accuracy > best_val_accuracy:\n",
        "            best_val_accuracy = val_accuracy\n",
        "            torch.save(model.state_dict(), config[\"model_save_path\"])\n",
        "            logging.info(\"New best model saved!\")\n",
        "\n",
        "        if early_stopping.early_stop:\n",
        "            logging.info(\"Early stopping\")\n",
        "            break\n",
        "\n",
        "    logging.info(\"Training completed. Evaluating on test set...\")\n",
        "\n",
        "    model.load_state_dict(torch.load(config[\"model_save_path\"]))\n",
        "    model.eval()\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            test_total += labels.size(0)\n",
        "            test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    test_accuracy = 100 * test_correct / test_total\n",
        "    logging.info(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
        "    logging.info(f\"Best model saved to {config['model_save_path']}\")\n",
        "\n",
        "    # Convert to TorchScript and save\n",
        "    example_input = torch.rand(1, 3, 224, 224).to(device)\n",
        "    torchscript_model = model.to_torchscript(example_input)\n",
        "    torch.jit.save(torchscript_model, config[\"torchscript_model_save_path\"])\n",
        "    logging.info(f\"TorchScript model saved to {config['torchscript_model_save_path']}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Mount Google Drive (if not already mounted)\n",
        "    try:\n",
        "        drive.mount(\"/content/drive\")\n",
        "    except:\n",
        "        print(\"Drive already mounted\")\n",
        "\n",
        "    # Load the config\n",
        "    config_path = \"/content/drive/MyDrive/Task2/config.yaml\"\n",
        "    config = load_config(config_path)\n",
        "\n",
        "    # Download and process videos\n",
        "    logging.info(\"Starting video download and processing...\")\n",
        "    processed_classes, total_classes = download_and_process_videos(\n",
        "        config[\"data_dir\"], config\n",
        "    )\n",
        "    logging.info(f\"Processed {processed_classes} out of {total_classes} classes\")\n",
        "\n",
        "    # Train the model\n",
        "    logging.info(\"Starting model training...\")\n",
        "    train_model(config[\"data_dir\"], config)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
